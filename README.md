# POV â†’ SO-ARM101 Teleoperation

Control a **simulated** SO-ARM101 robotic arm using a body-mounted camera and computer vision â€” no physical robot needed.

**Concept:** Wear a GoPro/phone on your chest â†’ MediaPipe tracks your arm â†’ simulated robot arm mirrors your movements in real-time.

## How It Works
```
Camera (chest-mounted) â†’ OpenCV â†’ MediaPipe Pose â†’ Joint Angles â†’ gym-soarm Simulator
```

1. **Camera** captures first-person view of your arms
2. **MediaPipe Pose** extracts 33 body landmarks at 30 FPS
3. **Geometric extraction** computes shoulder, elbow, wrist angles
4. **Smoothing filter** stabilizes the signal
5. **gym-soarm** (MuJoCo) renders the SO-ARM101 moving in real-time

## Quick Start
```bash
pip install mediapipe opencv-python numpy gym-soarm scipy
export MUJOCO_GL='egl'  # or 'glfw' on macOS
python src/main.py      # or: python -m src.main (from project root)
```

## Documentation
- ğŸ“‹ [Implementation Plan](IMPLEMENTATION-PLAN.md) â€” hour-by-hour build guide
- ğŸ”¬ [Research Report](RESEARCH.md) â€” deep technical research
- ğŸ¦¾ [SO-ARM101 Specs](research/so-arm101-specs.md)
- ğŸ‘ï¸ [Egocentric Vision](research/egocentric-vision.md)
- ğŸ‹ï¸ [Pose Estimation Comparison](research/pose-estimation-comparison.md)
- ğŸ”— [Related Projects](research/related-projects.md)

## Status
ğŸš§ Implementation phase â€” hackathon weekend project (Feb 2026)

## License
MIT
